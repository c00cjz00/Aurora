{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e87ada0-2467-4327-8dfa-a40bcbaff5a9",
   "metadata": {},
   "source": [
    "# 文本生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2781265f-c9f3-4edc-9885-c9f20efd413e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "Add_Binarry_Path=HOME+'/.local/bin'\n",
    "os.environ['PATH']=os.environ['PATH']+':'+Add_Binarry_Path\n",
    "current_foldr=!pwd\n",
    "current_foldr=current_foldr[0]\n",
    "current_foldr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c64958-1190-4149-9310-f54fdb3de260",
   "metadata": {},
   "source": [
    "## 確認CUDA版本, 以及否能使用GPU\n",
    "若無gpu 請點選右側->已連線->變更執行階段類型->T4 Gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db2daf-545d-4315-b8b0-62d379e79503",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95932c5e-f905-4e80-b542-4382f69122fa",
   "metadata": {},
   "source": [
    "## 安裝套件\n",
    "安裝完成後建議, 點選上方選單, 直接階段->重新啟動工作階段, 確保 library重置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4da06c-660b-4e6e-9f1f-b80d0ffe2963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install chromadb cohere gdown kaleido langchain openai pyngrok pypdf python-dotenv sentence-transformers tiktoken -q\n",
    "!pip install accelerate bitsandbytes hf_transfer huggingface_hub optimum transformers -q \n",
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fc5429-e6cd-4817-85bf-ab7545555147",
   "metadata": {},
   "source": [
    "## 模型下載"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d726499b-0a58-4d84-b98c-3954dd47551a",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%bash\n",
    "# Download model\n",
    "mkdir -p /work/g00cjz00/models/mistralai/Mixtral-8x7B-Instruct-v0.1\n",
    "HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download mistralai/Mixtral-8x7B-Instruct-v0.1 --local-dir /work/g00cjz00/models/mistralai/Mixtral-8x7B-Instruct-v0.1 --local-dir-use-symlinks False\n",
    "mkdir -p /work/g00cjz00/models/wangrongsheng/Aurora\n",
    "HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download wangrongsheng/Aurora --local-dir /work/g00cjz00/models/wangrongsheng/Aurora --local-dir-use-symlinks False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0ab63e-dc83-4d49-ad49-28e539fd3c05",
   "metadata": {},
   "source": [
    "## 程式碼啟動 WEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb784b9-c2e4-40e2-8fb2-c48de9023de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat << EOF >  src/web_demo_test.py\n",
    "from llmtuner import create_web_demo\n",
    "\n",
    "\n",
    "def main():\n",
    "    demo = create_web_demo()\n",
    "    demo.queue()\n",
    "    demo.launch(server_port=9000, server_name=\"$(hostname -s)\", share=False, inbrowser=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e45b3d1-bb4d-46d6-83af-716ceb9291af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "node_hostname=$(hostname -s)\n",
    "node_ip=$(cat /etc/hosts |grep \"$(hostname -a)\" | awk '{print $1}')\n",
    "# PORT\n",
    "#noed_port_genai=$(python -c \"import socket; s = socket.socket(socket.AF_INET, socket.SOCK_STREAM); s.bind(('', 0)); addr = s.getsockname(); s.close(); print(addr[1])\")\n",
    "noed_port_genai=9000\n",
    "\n",
    "# SSH FORWARDING\n",
    "ssh_cmd=\"ssh -L ${noed_port_genai}:${node_hostname}:${noed_port_genai} $(whoami)@t3-c4.nchc.org.tw\"\n",
    "echo \"SSH:\"\n",
    "echo ${ssh_cmd}\n",
    "echo \"\"\n",
    "echo \"URL: http://localhost:${noed_port_genai}\"\n",
    "echo \"\"\n",
    " \n",
    "# WEB\n",
    "CUDA_VISIBLE_DEVICES=0 HF_TOKEN='hf_' \\\n",
    "python src/web_demo_test.py \\\n",
    "    --model_name_or_path /work/g00cjz00/models/mistralai/Mixtral-8x7B-Instruct-v0.1 \\\n",
    "    --checkpoint_dir /work/g00cjz00/models/wangrongsheng/Aurora \\\n",
    "    --finetuning_type lora \\\n",
    "    --quantization_bit 4 \\\n",
    "    --template mistral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aab4d05-785b-428a-ab3d-ec3ebf99c2ba",
   "metadata": {},
   "source": [
    "## 程式碼啟動 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db5f202-876f-4dc5-b26e-c532f71b6a86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat << EOF >  src/api_demo_test.py\n",
    "import uvicorn\n",
    "from llmtuner import ChatModel, create_app\n",
    "\n",
    "def main():\n",
    "    chat_model = ChatModel()\n",
    "    app = create_app(chat_model)\n",
    "    print(\"Visit http://localhost:9000/docs for API document.\")\n",
    "    uvicorn.run(app, host=\"$(hostname -s)\", port=9000, workers=1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240f2cbe-cef4-42ab-9acd-3fa0eb45fc6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "node_hostname=$(hostname -s)\n",
    "node_ip=$(cat /etc/hosts |grep \"$(hostname -a)\" | awk '{print $1}')\n",
    "# PORT\n",
    "#noed_port_genai=$(python -c \"import socket; s = socket.socket(socket.AF_INET, socket.SOCK_STREAM); s.bind(('', 0)); addr = s.getsockname(); s.close(); print(addr[1])\")\n",
    "noed_port_genai=9000\n",
    "\n",
    "# SSH FORWARDING\n",
    "ssh_cmd=\"ssh -L ${noed_port_genai}:${node_hostname}:${noed_port_genai} $(whoami)@t3-c4.nchc.org.tw\"\n",
    "echo \"SSH:\"\n",
    "echo ${ssh_cmd}\n",
    "echo \"\"\n",
    "echo \"URL: http://localhost:${noed_port_genai}\"\n",
    "echo \"\"\n",
    " \n",
    "# API\n",
    "CUDA_VISIBLE_DEVICES=0 HF_TOKEN='hf_' \\\n",
    "python src/api_demo_test.py \\\n",
    "    --model_name_or_path /work/g00cjz00/models/mistralai/Mixtral-8x7B-Instruct-v0.1 \\\n",
    "    --checkpoint_dir /work/g00cjz00/models/wangrongsheng/Aurora \\\n",
    "    --finetuning_type lora \\\n",
    "    --quantization_bit 4 \\\n",
    "    --template mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4684a40e-edc8-4261-bf00-aa686822fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "##OEPNAPI\n",
    "#指定ChatGLM2-6B的API endpoint url，用langchain的ChatOpanAI类初始化一个ChatGLM的chat模型\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "        openai_api_base=\"http://gpn3002:9000/v1\",\n",
    "        openai_api_key=\"EMPTY\",\n",
    "        streaming=True,\n",
    "    )\n",
    "\n",
    "#使用会话实体内存，利用ChatGLM在会话过程中分析提到的实体(Entity)\n",
    "from langchain.chains.conversation.memory import ConversationEntityMemory\n",
    "from langchain.chains.conversation.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "entity_memory = ConversationEntityMemory(llm=llm, k=5 )\n",
    "\n",
    "#生成会话链\n",
    "from langchain.chains import ConversationChain\n",
    "Conversation = ConversationChain(\n",
    "            llm=llm, \n",
    "            prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "            memory=entity_memory,\n",
    "            verbose=True,\n",
    "        ) \n",
    "#开始测试\n",
    "#Conversation.run(\"寫一篇關於黃昏的描述, 要求細緻生動, 景色美好\")\n",
    "Conversation.run(\"小名手上有100顆蘋果, 送給小君10個, 又送給小林9個, 請問小名手上剩下幾個蘋果\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5747ea44-d9a7-42a7-82b6-2d2d4cc753eb",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15aa014-da25-4a97-a957-6c9420d7fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=1 python src/train_bash.py \\\n",
    "    --stage sft \\\n",
    "    --do_train \\\n",
    "    --model_name_or_path /work/g00cjz00/models/mistralai/Mixtral-8x7B-Instruct-v0.1 \\\n",
    "    --dataset alpaca_gpt4_zh \\\n",
    "    --template mistral \\\n",
    "    --finetuning_type lora \\\n",
    "    --quantization_bit 4 \\\n",
    "    --lora_target q_proj,v_proj \\\n",
    "    --output_dir path_to_sft_checkpoint \\\n",
    "    --overwrite_cache \\\n",
    "    --per_device_train_batch_size 1 \\\n",
    "    --gradient_accumulation_steps 4 \\\n",
    "    --lr_scheduler_type cosine \\\n",
    "    --logging_steps 100 \\\n",
    "    --save_steps 1000 \\\n",
    "    --learning_rate 5e-5 \\\n",
    "    --num_train_epochs 3.0 \\\n",
    "    --plot_loss \\\n",
    "    --fp16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad5d2a2-386d-485f-9d97-bbdedb32eea5",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1d7d45-9650-4e6a-a6b1-b77eb22ec705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python src/evaluate.py \\\n",
    "    --model_name_or_path /work/g00cjz00/models/mistralai/Mixtral-8x7B-Instruct-v0.1 \\\n",
    "    --checkpoint_dir /work/g00cjz00/models/wangrongsheng/Aurora/checkpoint-5000 \\\n",
    "    --template mistral \\\n",
    "    --finetuning_type lora \\\n",
    "    --quantization_bit 4 \\\n",
    "    --task cmmlu \\\n",
    "    --split test \\\n",
    "    --lang en \\\n",
    "    --n_shot 5 \\\n",
    "    --batch_size 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31273e6a-c0ed-45a5-9899-3ad2a7262ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Image_S_work-aurora_pytorch_2.1.2-cuda11.8-cudnn8-devel_opencv",
   "language": "python",
   "name": "s_work-aurora_pytorch_2.1.2-cuda11.8-cudnn8-devel_opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
